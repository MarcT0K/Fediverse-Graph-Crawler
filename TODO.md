# Possible improvements

- Use feather or parquet file instead of CSV
- Enable retries on failure
- Add a CLI interface
- Refactor the code for CSV writing
- Add some logging
- Improve timeout management
- Check whether the crawler does not land on any malicious/illegal website
- Unit testing
- Add an explicit user agent
- Package the code [if the codebase grows]
- Optimize the memory footprint [if the number of instances gets too high]
